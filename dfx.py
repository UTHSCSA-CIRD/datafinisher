""" Unpack and transform variables from a .CSV file generated by df.py
---------------------------------------------------------------------
usage: dfx.py [-l] [-h] [-o OUTFILE] [csvin]
    
"""


import argparse,csv
parser = argparse.ArgumentParser()
parser.add_argument("csvin",help="CSV input file generated by df.py")
parser.add_argument("-o","--outfile",help="CSV output file",default="")
parser.add_argument("-l","--log",help="Log verbose sql",action="store_true")
args = parser.parse_args()
dolog = args.log
from df_fn import xfieldj

testjson = """{"0": {"ix": 57016613993402840, "vf": null, "mc": "DX|PROF:NONPRIMARY", "cc": "GENERIC_KUH_DX_ID_2449", "cf": null, "lc": null, "st": "2012-07-11", "un": null, "vt": null, "tc": null, "nv": null, "qt": null}, "1": {"ix": 9697820316663506, "vf": null, "mc": "DiagObs:PAT_ENC_DX", "cc": "GENERIC_KUH_DX_ID_78949", "cf": null, "lc": null, "st": "2012-07-11", "un": null, "vt": null, "tc": null, "nv": null, "qt": null}, "2": {"ix": 55916360278195536, "vf": null, "mc": "DiagObs:PAT_ENC_DX", "cc": "GENERIC_KUH_DX_ID_78949", "cf": null, "lc": null, "st": "2012-07-11", "un": null, "vt": null, "tc": null, "nv": null, "qt": null}, "count": 3}"""

testargs = {'num_ix': {'field':'ix','transform':len},'any_vf': {'field':'vf','transform':any}
	    ,'encdx_mc': {'field':'mc','transform':lambda xx,refval: any([kk == refval for kk in xx]),'refval':'DiagObs:PAT_ENC_DX'}
	    ,'npdx_mc': {'field':'mc','transform':lambda xx,refval: any([kk == refval for kk in xx]),'refval':'DX|PROF:NONPRIMARY'}
	    ,'any_cc':{'field':'cc','transform':any}
	    ,'max_st':{'field':'st','transform':max}
	    ,'min_st':{'field':'st','transform':min}
	    ,'first_un':{'field':'un','transform':lambda xx: [kk for kk in xx if kk is not None][0] if any(xx) else None}
	    #,'':{'field':'','transform':None}
	    ,}

"""
Note: the following works:

xfieldj(testjson,**testargs['match_mc'])

TODO: What if the data argument is None or not JSON?
TODO: Iterate over a list of extractors for the same cell.
TODO: Have a list of lists of extractors and iterate over it for a line, returning the raw values for cells
      that are not JSON objects
TODO: Store the extractors in one dict per cell, with the dicts in a list with the same number of rows as 
      there are columns in the input data
TODO: Populate such a list from JSON strings in the first row of the input data and a set of rules for which
      default extractor goes with which set of conditions (and which extractors are invalid for which 
      conditions)
TODO: Generate the JSON strings in df.py by reading the data dictionary.
TODO: Figure out best way to hand over fresh output file from df.py directly to dfx.py
TODO: Start chopping out the no longer needed stuff from df.py
"""

def main(csvin):
  # read the csvin file
  myfhandle = open(csvin,'r')
  fr = csv.reader(myfhandle)
  myheader = fr.next()
  # get the header
  # parse the first row
  # iterate over the other rows and process them
  row0 = fr.next()
  # create an object with args for each column and iterate over it
  # write the processed rows to the outfile
  import pdb; pdb.set_trace()

if __name__ == '__main__':
    outfile = args.outfile
    # TODO: fix this path-unaware file name generator
    if outfile=="":
      outfile = "data_"+args.csvin
    main(args.csvin)
